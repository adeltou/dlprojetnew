"""
Test ULTRA-RAPIDE pour U-Net
Utilise seulement 200 images pour tester que tout fonctionne
Dur√©e estim√©e : 2-3 minutes
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import numpy as np
import tensorflow as tf
from tensorflow import keras
import time

from models.unet_scratch import create_unet_model
from models.model_utils import DiceCoefficient, IoUMetric
from preprocessing.data_loader import RDD2022DataLoader
from preprocessing.preprocessing import ImagePreprocessor
from utils.config import *
from utils.helpers import *


class FastUNetDataGenerator(keras.utils.Sequence):
    """
    Data Generator RAPIDE - utilise seulement un subset des donn√©es
    """
    
    def __init__(self,
                 data_loader: RDD2022DataLoader,
                 preprocessor: ImagePreprocessor,
                 max_samples: int = 200,  # SEULEMENT 200 images !
                 batch_size: int = 16,
                 shuffle: bool = True):
        """
        Args:
            data_loader: Instance de RDD2022DataLoader
            preprocessor: Instance de ImagePreprocessor
            max_samples: Nombre maximum d'images √† utiliser
            batch_size: Taille des batches
            shuffle: M√©langer les donn√©es
        """
        self.data_loader = data_loader
        self.preprocessor = preprocessor
        self.batch_size = batch_size
        self.shuffle = shuffle
        
        # Utiliser seulement un subset des donn√©es
        total_samples = len(self.data_loader)
        self.max_samples = min(max_samples, total_samples)
        
        # Indices al√©atoires
        self.indices = np.random.choice(total_samples, self.max_samples, replace=False)
        
        if self.shuffle:
            np.random.shuffle(self.indices)
        
        print(f"‚ö° Mode RAPIDE: Utilise {self.max_samples} images sur {total_samples}")
    
    def __len__(self):
        """Nombre de batches par epoch"""
        return int(np.ceil(self.max_samples / self.batch_size))
    
    def __getitem__(self, idx):
        """G√©n√®re un batch"""
        start_idx = idx * self.batch_size
        end_idx = min((idx + 1) * self.batch_size, self.max_samples)
        
        batch_indices = self.indices[start_idx:end_idx]
        
        images_list = []
        masks_list = []
        
        for i in batch_indices:
            # Charger
            image, mask, _ = self.data_loader[i]
            
            # Pr√©traiter
            image = self.preprocessor.preprocess_image(image)
            mask = self.preprocessor.preprocess_mask(mask)
            
            images_list.append(image)
            masks_list.append(mask)
        
        # Convertir
        images_batch = np.array(images_list, dtype=np.float32)
        masks_batch = np.array(masks_list, dtype=np.uint8)
        
        # Masks en categorical
        masks_categorical = np.array([
            self.preprocessor.mask_to_categorical(mask)
            for mask in masks_batch
        ], dtype=np.float32)
        
        return images_batch, masks_categorical
    
    def on_epoch_end(self):
        """Appel√© √† la fin de chaque epoch"""
        if self.shuffle:
            np.random.shuffle(self.indices)


def ultra_fast_test(data_path: str):
    """
    Test ULTRA-RAPIDE avec seulement 200 images et 2 epochs
    Dur√©e estim√©e : 2-3 minutes
    """
    print("\n" + "=" * 100)
    print("‚ö° TEST ULTRA-RAPIDE U-NET (200 IMAGES, 2 EPOCHS)")
    print("=" * 100)
    print("\nüéØ Objectif : V√©rifier que l'entra√Ænement fonctionne")
    print("‚è±Ô∏è  Dur√©e estim√©e : 2-3 minutes")
    print("=" * 100)
    
    # Seeds
    set_seeds(RANDOM_SEED)
    
    # Cr√©er les dossiers
    create_directories()
    
    # ========================================================================
    # 1. CHARGEMENT DES DONN√âES (MODE RAPIDE)
    # ========================================================================
    print("\nüì¶ Chargement des donn√©es (mode rapide)...")
    
    train_loader = RDD2022DataLoader(data_path, split='train')
    val_loader = RDD2022DataLoader(data_path, split='val')
    
    preprocessor = ImagePreprocessor(target_size=IMG_SIZE, normalize=True)
    
    # Cr√©er les generators RAPIDES
    train_generator = FastUNetDataGenerator(
        data_loader=train_loader,
        preprocessor=preprocessor,
        max_samples=200,  # Seulement 200 images !
        batch_size=16,
        shuffle=True
    )
    
    val_generator = FastUNetDataGenerator(
        data_loader=val_loader,
        preprocessor=preprocessor,
        max_samples=50,  # Seulement 50 images pour validation !
        batch_size=16,
        shuffle=False
    )
    
    print(f"‚úÖ Donn√©es charg√©es:")
    print(f"  - Train: {200} images (au lieu de {len(train_loader)})")
    print(f"  - Val: {50} images (au lieu de {len(val_loader)})")
    print(f"  - Train batches: {len(train_generator)}")
    print(f"  - Val batches: {len(val_generator)}")
    
    # ========================================================================
    # 2. CR√âATION DU MOD√àLE (PETIT)
    # ========================================================================
    print("\nüèóÔ∏è  Cr√©ation du mod√®le U-Net (version petite)...")
    
    # Utiliser moins de filtres pour aller plus vite
    model = create_unet_model(
        input_shape=IMG_SIZE + (IMG_CHANNELS,),
        num_classes=NUM_CLASSES + 1,
        filters_base=32,  # 32 au lieu de 64 = 4x plus rapide !
        compile_model=False
    )
    
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=1e-3),  # LR plus √©lev√© pour test
        loss='categorical_crossentropy',
        metrics=['accuracy', DiceCoefficient(), IoUMetric()]
    )
    
    print("‚úÖ Mod√®le cr√©√©")
    print(f"  - Param√®tres: {model.count_params():,}")
    
    # ========================================================================
    # 3. CALLBACKS SIMPLES
    # ========================================================================
    print("\nüìä Configuration des callbacks...")
    
    callbacks = [
        keras.callbacks.ProgbarLogger(),
        keras.callbacks.History()
    ]
    
    print("‚úÖ Callbacks configur√©s (mode simple)")
    
    # ========================================================================
    # 4. ENTRA√éNEMENT
    # ========================================================================
    print("\nüöÄ D√©but de l'entra√Ænement...")
    print("=" * 100)
    
    start_time = time.time()
    
    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=2,
        callbacks=callbacks,
        verbose=1
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 100)
    print("‚úÖ TEST TERMIN√â!")
    print("=" * 100)
    print(f"‚è±Ô∏è  Temps total: {format_time(training_time)}")
    
    # ========================================================================
    # 5. R√âSULTATS
    # ========================================================================
    print("\nüìä R√©sultats finaux:")
    print("-" * 100)
    
    final_metrics = {
        'loss': history.history['loss'][-1],
        'accuracy': history.history['accuracy'][-1],
        'dice': history.history['dice_coefficient'][-1],
        'iou': history.history['iou'][-1],
        'val_loss': history.history['val_loss'][-1],
        'val_accuracy': history.history['val_accuracy'][-1],
        'val_dice': history.history['val_dice_coefficient'][-1],
        'val_iou': history.history['val_iou'][-1]
    }
    
    for name, value in final_metrics.items():
        print(f"  {name:20s}: {value:.4f}")
    
    print("-" * 100)
    
    # ========================================================================
    # 6. CONCLUSION
    # ========================================================================
    print("\n" + "=" * 100)
    print("üéâ CONCLUSION DU TEST")
    print("=" * 100)
    
    if final_metrics['val_dice'] > 0.3:
        print("‚úÖ Le mod√®le apprend correctement!")
        print("‚úÖ Dice coefficient > 0.3 : C'est bon signe")
        print("\nüí° Tu peux maintenant lancer l'entra√Ænement complet:")
        print("   python training/train_unet.py")
    else:
        print("‚ö†Ô∏è  Le mod√®le apprend lentement (normal pour 2 epochs)")
        print("‚ö†Ô∏è  Mais le code fonctionne correctement!")
        print("\nüí° Pour de meilleurs r√©sultats, lance l'entra√Ænement complet:")
        print("   python training/train_unet.py")
    
    print("=" * 100)
    
    return model, history


if __name__ == "__main__":
    # Chemin du dataset
    DATA_PATH = "C:/Users/DELL/Desktop/dataset/RDD_SPLIT"
    
    # V√©rifier que le chemin existe
    if not os.path.exists(DATA_PATH):
        print("\n" + "=" * 100)
        print("‚ùå ERREUR: Le chemin du dataset n'existe pas!")
        print("=" * 100)
        print(f"\nChemin sp√©cifi√©: {DATA_PATH}")
        print("\nVeuillez modifier la variable DATA_PATH dans ce script.")
        print("=" * 100)
    else:
        # Lancer le test ultra-rapide
        model, history = ultra_fast_test(DATA_PATH)
