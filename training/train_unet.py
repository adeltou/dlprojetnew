"""
Script d'Entra√Ænement pour U-Net
Entra√Æne le mod√®le U-Net from scratch sur le dataset RDD2022
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

import numpy as np
import tensorflow as tf
from tensorflow import keras
import time
from datetime import datetime

from models.unet_scratch import create_unet_model
from models.model_utils import DiceCoefficient, IoUMetric
from preprocessing.data_loader import RDD2022DataLoader
from preprocessing.preprocessing import ImagePreprocessor, DataAugmentorSimple
from training.callbacks import create_callbacks, TrainingProgressCallback
from utils.config import *
from utils.helpers import *


class UNetDataGenerator(keras.utils.Sequence):
    """
    Data Generator pour U-Net
    G√©n√®re des batches d'images et masques pour l'entra√Ænement
    """
    
    def __init__(self,
                 data_loader: RDD2022DataLoader,
                 preprocessor: ImagePreprocessor,
                 batch_size: int = BATCH_SIZE,
                 shuffle: bool = True,
                 augment: bool = False):
        """
        Args:
            data_loader: Instance de RDD2022DataLoader
            preprocessor: Instance de ImagePreprocessor
            batch_size: Taille des batches
            shuffle: M√©langer les donn√©es √† chaque epoch
            augment: Appliquer l'augmentation de donn√©es
        """
        self.data_loader = data_loader
        self.preprocessor = preprocessor
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.augment = augment
        
        # Cr√©er l'augmenteur si n√©cessaire
        if self.augment:
            self.augmentor = DataAugmentorSimple()
        
        # Indices
        self.indices = np.arange(len(self.data_loader))
        
        # M√©langer au d√©but
        if self.shuffle:
            np.random.shuffle(self.indices)
    
    def __len__(self):
        """Nombre de batches par epoch"""
        return int(np.ceil(len(self.data_loader) / self.batch_size))
    
    def __getitem__(self, idx):
        """
        G√©n√®re un batch de donn√©es
        
        Args:
            idx: Index du batch
            
        Returns:
            (images_batch, masks_batch)
        """
        # Indices pour ce batch
        batch_indices = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]
        
        # Listes pour stocker les donn√©es
        images_list = []
        masks_list = []
        
        for i in batch_indices:
            # Charger l'image et le masque
            image, mask, _ = self.data_loader[i]
            
            # Pr√©traiter
            image = self.preprocessor.preprocess_image(image)
            mask = self.preprocessor.preprocess_mask(mask)
            
            # Augmenter si demand√©
            if self.augment:
                image, mask = self.augmentor.augment(image, mask)
            
            images_list.append(image)
            masks_list.append(mask)
        
        # Convertir en arrays numpy
        images_batch = np.array(images_list, dtype=np.float32)
        masks_batch = np.array(masks_list, dtype=np.uint8)
        
        # Convertir les masques en categorical
        masks_categorical = np.array([
            self.preprocessor.mask_to_categorical(mask)
            for mask in masks_batch
        ], dtype=np.float32)
        
        return images_batch, masks_categorical
    
    def on_epoch_end(self):
        """Appel√© √† la fin de chaque epoch"""
        if self.shuffle:
            np.random.shuffle(self.indices)


def train_unet(data_path: str,
               epochs: int = EPOCHS,
               batch_size: int = BATCH_SIZE,
               learning_rate: float = LEARNING_RATE,
               use_augmentation: bool = True,
               save_results: bool = True):
    """
    Fonction principale pour entra√Æner U-Net
    
    Args:
        data_path: Chemin vers le dataset RDD_SPLIT
        epochs: Nombre d'epochs
        batch_size: Taille du batch
        learning_rate: Learning rate
        use_augmentation: Utiliser l'augmentation de donn√©es
        save_results: Sauvegarder les r√©sultats
        
    Returns:
        (model, history)
    """
    print("\n" + "=" * 100)
    print("ENTRA√éNEMENT U-NET - ROAD DAMAGE DETECTION")
    print("=" * 100)
    
    # ========================================================================
    # 1. CONFIGURATION
    # ========================================================================
    print("\nüîß PHASE 1: Configuration")
    print("-" * 100)
    
    # Seeds pour reproductibilit√©
    set_seeds(RANDOM_SEED)
    
    # Cr√©er les dossiers
    create_directories()
    
    print(f"‚úÖ Configuration:")
    print(f"  - Epochs: {epochs}")
    print(f"  - Batch size: {batch_size}")
    print(f"  - Learning rate: {learning_rate}")
    print(f"  - Image size: {IMG_SIZE}")
    print(f"  - Augmentation: {use_augmentation}")
    
    # ========================================================================
    # 2. CHARGEMENT DES DONN√âES
    # ========================================================================
    print("\nüì¶ PHASE 2: Chargement des donn√©es")
    print("-" * 100)
    
    # Charger les datasets
    train_loader = RDD2022DataLoader(data_path, split='train')
    val_loader = RDD2022DataLoader(data_path, split='val')
    
    print(f"‚úÖ Donn√©es charg√©es:")
    print(f"  - Train: {len(train_loader)} images")
    print(f"  - Val: {len(val_loader)} images")
    
    # Cr√©er le pr√©processeur
    preprocessor = ImagePreprocessor(target_size=IMG_SIZE, normalize=True)
    
    # Cr√©er les data generators
    train_generator = UNetDataGenerator(
        data_loader=train_loader,
        preprocessor=preprocessor,
        batch_size=batch_size,
        shuffle=True,
        augment=use_augmentation
    )
    
    val_generator = UNetDataGenerator(
        data_loader=val_loader,
        preprocessor=preprocessor,
        batch_size=batch_size,
        shuffle=False,
        augment=False  # Pas d'augmentation pour la validation
    )
    
    print(f"‚úÖ Data generators cr√©√©s:")
    print(f"  - Train batches: {len(train_generator)}")
    print(f"  - Val batches: {len(val_generator)}")
    
    # ========================================================================
    # 3. CR√âATION DU MOD√àLE
    # ========================================================================
    print("\nüèóÔ∏è  PHASE 3: Cr√©ation du mod√®le U-Net")
    print("-" * 100)
    
    # Cr√©er le mod√®le
    model = create_unet_model(
        input_shape=IMG_SIZE + (IMG_CHANNELS,),
        num_classes=NUM_CLASSES + 1,
        filters_base=64,
        compile_model=False
    )
    
    # Compiler avec des m√©triques personnalis√©es
    model.compile(
        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),
        loss='categorical_crossentropy',
        metrics=[
            'accuracy',
            DiceCoefficient(),
            IoUMetric()
        ]
    )
    
    print("‚úÖ Mod√®le U-Net cr√©√© et compil√©")
    
    # Afficher le r√©sum√©
    model.summary()
    
    # ========================================================================
    # 4. CR√âATION DES CALLBACKS
    # ========================================================================
    print("\nüìä PHASE 4: Configuration des callbacks")
    print("-" * 100)
    
    callbacks = create_callbacks(
        model_name='unet_rdd2022',
        monitor='val_dice_coefficient',
        patience_early_stop=CALLBACKS_CONFIG['early_stopping']['patience'],
        patience_reduce_lr=CALLBACKS_CONFIG['reduce_lr']['patience'],
        save_best_only=True
    )
    
    # Ajouter le callback de progression
    callbacks.append(TrainingProgressCallback(epochs=epochs))
    
    # ========================================================================
    # 5. ENTRA√éNEMENT
    # ========================================================================
    print("\nüöÄ PHASE 5: Entra√Ænement du mod√®le")
    print("-" * 100)
    print(f"D√©but: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("-" * 100)
    
    start_time = time.time()
    
    # Entra√Æner le mod√®le
    history = model.fit(
        train_generator,
        validation_data=val_generator,
        epochs=epochs,
        callbacks=callbacks,
        verbose=1
    )
    
    training_time = time.time() - start_time
    
    print("\n" + "=" * 100)
    print("‚úÖ ENTRA√éNEMENT TERMIN√â!")
    print("=" * 100)
    print(f"Temps total: {format_time(training_time)}")
    print(f"Fin: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # ========================================================================
    # 6. √âVALUATION FINALE
    # ========================================================================
    print("\nüìà PHASE 6: √âvaluation finale")
    print("-" * 100)
    
    # √âvaluer sur le set de validation
    val_results = model.evaluate(val_generator, verbose=0)
    
    print("\nüìä R√©sultats sur le set de validation:")
    print("-" * 100)
    for metric_name, value in zip(model.metrics_names, val_results):
        print(f"  {metric_name:25s}: {value:.4f}")
    print("-" * 100)
    
    # ========================================================================
    # 7. SAUVEGARDE DES R√âSULTATS
    # ========================================================================
    if save_results:
        print("\nüíæ PHASE 7: Sauvegarde des r√©sultats")
        print("-" * 100)
        
        # Cr√©er un dictionnaire avec les r√©sultats
        results = {
            'model': 'U-Net',
            'architecture': 'from_scratch',
            'epochs_trained': len(history.history['loss']),
            'training_time_seconds': training_time,
            'final_metrics': {
                metric_name: float(value)
                for metric_name, value in zip(model.metrics_names, val_results)
            },
            'history': {
                key: [float(v) for v in values]
                for key, values in history.history.items()
            },
            'config': {
                'batch_size': batch_size,
                'learning_rate': learning_rate,
                'image_size': IMG_SIZE,
                'num_classes': NUM_CLASSES + 1,
                'augmentation': use_augmentation
            }
        }
        
        # Sauvegarder en JSON
        results_path = os.path.join(RESULTS_ROOT, 'unet_training_results.json')
        save_results_json(results, results_path)
        
        # Visualiser l'historique d'entra√Ænement
        fig_path = os.path.join(FIGURES_DIR, 'unet_training_history.png')
        plot_training_history(history.history, save_path=fig_path)
    
    print("\n" + "=" * 100)
    print("‚úÖ TOUS LES TRAITEMENTS TERMIN√âS!")
    print("=" * 100)
    
    return model, history


def quick_test_training(data_path: str):
    """
    Test rapide de l'entra√Ænement avec 2 epochs
    
    Args:
        data_path: Chemin vers le dataset
    """
    print("\n" + "=" * 100)
    print("TEST RAPIDE DE L'ENTRA√éNEMENT U-NET (2 EPOCHS)")
    print("=" * 100)
    
    model, history = train_unet(
        data_path=data_path,
        epochs=2,
        batch_size=8,
        learning_rate=1e-4,
        use_augmentation=False,
        save_results=False
    )
    
    print("\n‚úÖ Test rapide r√©ussi!")
    
    return model, history


if __name__ == "__main__":
    # IMPORTANT: Modifier ce chemin selon votre configuration
    DATA_PATH = "C:/Users/DELL/Desktop/dataset/RDD_SPLIT"
    
    # V√©rifier que le chemin existe
    if not os.path.exists(DATA_PATH):
        print("\n" + "=" * 100)
        print("‚ùå ERREUR: Le chemin du dataset n'existe pas!")
        print("=" * 100)
        print(f"\nChemin sp√©cifi√©: {DATA_PATH}")
        print("\nVeuillez modifier la variable DATA_PATH dans ce script.")
        print("=" * 100)
    else:
        # Choix de l'entra√Ænement
        print("\n" + "=" * 100)
        print("ENTRA√éNEMENT U-NET")
        print("=" * 100)
        print("\n1. Test rapide (2 epochs)")
        print("2. Entra√Ænement complet (100 epochs)")
        
        choice = input("\nVotre choix (1 ou 2): ")
        
        if choice == "1":
            # Test rapide
            model, history = quick_test_training(DATA_PATH)
        elif choice == "2":
            # Entra√Ænement complet
            model, history = train_unet(
                data_path=DATA_PATH,
                epochs=EPOCHS,
                batch_size=BATCH_SIZE,
                learning_rate=LEARNING_RATE,
                use_augmentation=True,
                save_results=True
            )
        else:
            print("\n‚ùå Choix invalide!")
